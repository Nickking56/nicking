#include <cuda_runtime.h>
#include <stdio.h>
#include "device_launch_parameters.h"
#include <iostream>
#include <cmath>
#include <cstdlib>

#define TILE_WIDTH 16 // This can be changed to 2, 5, 10, 25 as required

__global__ void MatrixMulKernel(float* P, float* M, float* N, int Width) {
    __shared__ float Ms[TILE_WIDTH][TILE_WIDTH];
    __shared__ float Ns[TILE_WIDTH][TILE_WIDTH];

    int bx = blockIdx.x;  int by = blockIdx.y;
    int tx = threadIdx.x; int ty = threadIdx.y;

    // Identify the row and column of the P element to work on
    int Row = by * TILE_WIDTH + ty;
    int Col = bx * TILE_WIDTH + tx;

    float Pvalue = 0;
    // Loop over the M and N tiles required to compute the P element
    for (int m = 0; m < (Width - 1) / TILE_WIDTH + 1; ++m) {
        // Collaborative loading of M and N tiles into shared memory
        if (Row < Width && m * TILE_WIDTH + tx < Width)
            Ms[ty][tx] = M[Row * Width + m * TILE_WIDTH + tx];
        else
            Ms[ty][tx] = 0.0;

        if (Col < Width && m * TILE_WIDTH + ty < Width)
            Ns[ty][tx] = N[(m * TILE_WIDTH + ty) * Width + Col];
        else
            Ns[ty][tx] = 0.0;

        __syncthreads();

        for (int k = 0; k < TILE_WIDTH; ++k)
            Pvalue += Ms[ty][k] * Ns[k][tx];

        __syncthreads();
    }
    if (Row < Width && Col < Width)
        P[Row * Width + Col] = Pvalue;
}


void initializeMatrix(float* mat, int size) {
    for (int i = 0; i < size; i++) {
        mat[i] = rand() / (float)RAND_MAX;
    }
}

void matrixMultiplicationCPU(float* A, float* B, float* C, int N) {
    for (int row = 0; row < N; row++) {
        for (int col = 0; col < N; col++) {
            float sum = 0.0f;
            for (int n = 0; n < N; n++) {
                sum += A[row * N + n] * B[n * N + col];
            }
            C[row * N + col] = sum;
        }
    }
}

bool checkResult(float* hostRef, float* gpuRef, int N, float tol = 1e-5) {
    for (int i = 0; i < N * N; i++) {
        if (fabs(hostRef[i] - gpuRef[i]) > tol) {
            return false;
        }
    }
    return true;
}

int main() {
    int N = 1024; // Matrix size, can be varied
    size_t bytes = N * N * sizeof(float);

    float* h_M, * h_N, * h_P, * h_P_ref;
    float* d_M, * d_N, * d_P;

    h_M = (float*)malloc(bytes);
    h_N = (float*)malloc(bytes);
    h_P = (float*)malloc(bytes);
    h_P_ref = (float*)malloc(bytes);

    initializeMatrix(h_M, N * N);
    initializeMatrix(h_N, N * N);

    cudaMalloc(&d_M, bytes);
    cudaMalloc(&d_N, bytes);
    cudaMalloc(&d_P, bytes);

    cudaMemcpy(d_M, h_M, bytes, cudaMemcpyHostToDevice);
    cudaMemcpy(d_N, h_N, bytes, cudaMemcpyHostToDevice);

    dim3 block(TILE_WIDTH, TILE_WIDTH);
    dim3 grid((N + block.x - 1) / block.x, (N + block.y - 1) / block.y);

    MatrixMulKernel << <grid, block >> > (d_P, d_M, d_N, N);

    cudaMemcpy(h_P, d_P, bytes, cudaMemcpyDeviceToHost);

    // Compute on CPU for comparison
    matrixMultiplicationCPU(h_M, h_N, h_P_ref, N);

    // Check results
    if (checkResult(h_P_ref, h_P, N)) {
        printf("Test PASSED\n");
    }
    else {
        printf("Test FAILED\n");
    }

    // Free memory
    cudaFree(d_M);
    cudaFree(d_N);
    cudaFree(d_P);
    free(h_M);
    free(h_N);
    free(h_P);
    free(h_P_ref);

    return 0;
}
